{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to read a df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_csv_to_dataframe(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv_to_dataframe(\"/home/nalin21478/ML-Flight-Delay-Prediction/Data/smoted_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropping Dep_delay column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['DEP_DELAY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>DEST</th>\n",
       "      <th>CRS_ELAPSED_TIME</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Wind Gust</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Condition</th>\n",
       "      <th>sch_dep</th>\n",
       "      <th>sch_arr</th>\n",
       "      <th>Delayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.848855</td>\n",
       "      <td>-0.711515</td>\n",
       "      <td>0.761435</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>-0.038486</td>\n",
       "      <td>15</td>\n",
       "      <td>2.069328</td>\n",
       "      <td>2.821704</td>\n",
       "      <td>-0.727985</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.33048</td>\n",
       "      <td>-1.390801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>1.217334</td>\n",
       "      <td>1.354774</td>\n",
       "      <td>0.761435</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>-0.038486</td>\n",
       "      <td>15</td>\n",
       "      <td>2.069328</td>\n",
       "      <td>2.821704</td>\n",
       "      <td>-0.727985</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.33048</td>\n",
       "      <td>-1.390801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.372043</td>\n",
       "      <td>-0.224999</td>\n",
       "      <td>0.761435</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>-0.038486</td>\n",
       "      <td>15</td>\n",
       "      <td>2.069328</td>\n",
       "      <td>2.821704</td>\n",
       "      <td>-0.727985</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.33048</td>\n",
       "      <td>-1.390801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.480789</td>\n",
       "      <td>-0.365448</td>\n",
       "      <td>0.761435</td>\n",
       "      <td>0.184485</td>\n",
       "      <td>-0.038486</td>\n",
       "      <td>15</td>\n",
       "      <td>2.069328</td>\n",
       "      <td>2.821704</td>\n",
       "      <td>-0.727985</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.33048</td>\n",
       "      <td>-1.390801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.723378</td>\n",
       "      <td>-0.572189</td>\n",
       "      <td>0.494669</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>-0.038486</td>\n",
       "      <td>15</td>\n",
       "      <td>1.907431</td>\n",
       "      <td>2.563372</td>\n",
       "      <td>-0.555007</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.33048</td>\n",
       "      <td>-1.390801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MONTH  DAY_OF_MONTH  DAY_OF_WEEK  DEST  CRS_ELAPSED_TIME  DISTANCE  \\\n",
       "0     11             1            5    10         -0.848855 -0.711515   \n",
       "1     11             1            5    28          1.217334  1.354774   \n",
       "2     11             1            5    20         -0.372043 -0.224999   \n",
       "3     11             1            5    30         -0.480789 -0.365448   \n",
       "4     11             1            5     1         -0.723378 -0.572189   \n",
       "\n",
       "   Temperature  Dew Point  Humidity  Wind  Wind Speed  Wind Gust  Pressure  \\\n",
       "0     0.761435   0.184485 -0.038486    15    2.069328   2.821704 -0.727985   \n",
       "1     0.761435   0.184485 -0.038486    15    2.069328   2.821704 -0.727985   \n",
       "2     0.761435   0.184485 -0.038486    15    2.069328   2.821704 -0.727985   \n",
       "3     0.761435   0.184485 -0.038486    15    2.069328   2.821704 -0.727985   \n",
       "4     0.494669   0.002399 -0.038486    15    1.907431   2.563372 -0.555007   \n",
       "\n",
       "   Condition  sch_dep   sch_arr  Delayed  \n",
       "0          3 -2.33048 -1.390801        0  \n",
       "1          3 -2.33048 -1.390801        0  \n",
       "2          3 -2.33048 -1.390801        1  \n",
       "3          3 -2.33048 -1.390801        0  \n",
       "4          3 -2.33048 -1.390801        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to do Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import joblib\n",
    "\n",
    "def evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, classifier, num_folds=10, model_name=None):\n",
    "\n",
    "    k_fold = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
    "    \n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "\n",
    "    for train_indices, val_indices in k_fold.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train[train_indices], X_train[val_indices]\n",
    "        y_fold_train, y_fold_val = y_train[train_indices], y_train[val_indices]\n",
    "\n",
    "        \n",
    "        classifier.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    \n",
    "        y_val_pred = classifier.predict(X_fold_val)\n",
    "\n",
    "     \n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_val_pred)\n",
    "        accuracies.append(fold_accuracy)\n",
    "\n",
    "   \n",
    "    average_accuracy = sum(accuracies) / num_folds\n",
    "    print(f'Average Accuracy Train: {average_accuracy*100}')\n",
    "\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy Test: {accuracy*100:.2f}%')\n",
    "    \n",
    "    \n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print('Classification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    if model_name is not None:\n",
    "        joblib.dump(classifier, f'{model_name}.pkl') \n",
    "    return class_report,confusion_matrix\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Independent_features = data.iloc[:, :-1].values\n",
    "dependent_feature = data.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Independent_features, dependent_feature, test_size=0.2, random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE\n",
      "\n",
      "Average Accuracy Train: 86.80182209188659\n",
      "Accuracy Test: 86.67%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      4623\n",
      "           1       0.87      0.87      0.87      4754\n",
      "\n",
      "    accuracy                           0.87      9377\n",
      "   macro avg       0.87      0.87      0.87      9377\n",
      "weighted avg       0.87      0.87      0.87      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4009  614]\n",
      " [ 636 4118]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('              precision    recall  f1-score   support\\n\\n           0       0.86      0.87      0.87      4623\\n           1       0.87      0.87      0.87      4754\\n\\n    accuracy                           0.87      9377\\n   macro avg       0.87      0.87      0.87      9377\\nweighted avg       0.87      0.87      0.87      9377\\n',\n",
       " <function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(\"DECISION TREE\\n\")\n",
    "decision_tree=DecisionTreeClassifier(criterion='entropy',splitter='best',class_weight='balanced')\n",
    "\n",
    "evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, decision_tree, num_folds=10,model_name='decision_tree_entropy_smote'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 91.11853052519328\n",
      "Accuracy Test: 91.29%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91      4623\n",
      "           1       0.93      0.89      0.91      4754\n",
      "\n",
      "    accuracy                           0.91      9377\n",
      "   macro avg       0.91      0.91      0.91      9377\n",
      "weighted avg       0.91      0.91      0.91      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4308  315]\n",
      " [ 502 4252]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"RANDOM FOREST CLASSIFIER \\n\")\n",
    "random_forest_classifier = RandomForestClassifier(criterion='entropy',n_estimators=1700)\n",
    "\n",
    "random_forest_classifier_report,random_forest_classifier_matrix=evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, random_forest_classifier, num_folds=10,model_name='random_forest_smote')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAIVE BAYES CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 58.00825593175153\n",
      "Accuracy Test: 58.14%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.51      0.55      4623\n",
      "           1       0.58      0.65      0.61      4754\n",
      "\n",
      "    accuracy                           0.58      9377\n",
      "   macro avg       0.58      0.58      0.58      9377\n",
      "weighted avg       0.58      0.58      0.58      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2356 2267]\n",
      " [1658 3096]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('              precision    recall  f1-score   support\\n\\n           0       0.59      0.51      0.55      4623\\n           1       0.58      0.65      0.61      4754\\n\\n    accuracy                           0.58      9377\\n   macro avg       0.58      0.58      0.58      9377\\nweighted avg       0.58      0.58      0.58      9377\\n',\n",
       " <function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "print(\"NAIVE BAYES CLASSIFIER \\n\")\n",
    "\n",
    "# Initialize the Naive Bayes Classifier\n",
    "nb_classifier = GaussianNB(var_smoothing=0.001)\n",
    "\n",
    "evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, nb_classifier, num_folds=10,model_name='naive_bayes_smote')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 80.93056500488757\n",
      "Accuracy Test: 81.21%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78      4623\n",
      "           1       0.76      0.93      0.83      4754\n",
      "\n",
      "    accuracy                           0.81      9377\n",
      "   macro avg       0.83      0.81      0.81      9377\n",
      "weighted avg       0.83      0.81      0.81      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3198 1425]\n",
      " [ 337 4417]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('              precision    recall  f1-score   support\\n\\n           0       0.90      0.69      0.78      4623\\n           1       0.76      0.93      0.83      4754\\n\\n    accuracy                           0.81      9377\\n   macro avg       0.83      0.81      0.81      9377\\nweighted avg       0.83      0.81      0.81      9377\\n',\n",
       " <function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"KNN CLASSIFIER \\n\")\n",
    "evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, knn_classifier, num_folds=10,model_name='knn_classifier_smote')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADIENT BOOSTING CLASSIFIER \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy Train: 91.8917593530614\n",
      "Accuracy Test: 91.96%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92      4623\n",
      "           1       0.98      0.86      0.92      4754\n",
      "\n",
      "    accuracy                           0.92      9377\n",
      "   macro avg       0.93      0.92      0.92      9377\n",
      "weighted avg       0.93      0.92      0.92      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4537   86]\n",
      " [ 668 4086]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('              precision    recall  f1-score   support\\n\\n           0       0.87      0.98      0.92      4623\\n           1       0.98      0.86      0.92      4754\\n\\n    accuracy                           0.92      9377\\n   macro avg       0.93      0.92      0.92      9377\\nweighted avg       0.93      0.92      0.92      9377\\n',\n",
       " <function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(subsample=1.0, n_estimators=950)\n",
    "print(\"GRADIENT BOOSTING CLASSIFIER \\n\")\n",
    "evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, gb_classifier, num_folds=10,model_name='gb_classifier_smote')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi class logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 55.44325459877365\n",
      "Accuracy Test: 55.34%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55      4623\n",
      "           1       0.56      0.56      0.56      4754\n",
      "\n",
      "    accuracy                           0.55      9377\n",
      "   macro avg       0.55      0.55      0.55      9377\n",
      "weighted avg       0.55      0.55      0.55      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2518 2105]\n",
      " [2083 2671]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_regression_classifier = LogisticRegression(C=0.001,max_iter=100,multi_class='ovr',penalty='l1',solver='liblinear')\n",
    "\n",
    "print(\"LOGISTIC REGRESSION CLASSIFIER \\n\")\n",
    "logistic_regression_report, logistic_regression_matrix = evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, logistic_regression_classifier, num_folds=10,model_name='logistic_regression_smote')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 92.79564631653781\n",
      "Accuracy Test: 92.66%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      4623\n",
      "           1       0.98      0.87      0.92      4754\n",
      "\n",
      "    accuracy                           0.93      9377\n",
      "   macro avg       0.93      0.93      0.93      9377\n",
      "weighted avg       0.93      0.93      0.93      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4541   82]\n",
      " [ 606 4148]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('              precision    recall  f1-score   support\\n\\n           0       0.88      0.98      0.93      4623\\n           1       0.98      0.87      0.92      4754\\n\\n    accuracy                           0.93      9377\\n   macro avg       0.93      0.93      0.93      9377\\nweighted avg       0.93      0.93      0.93      9377\\n',\n",
       " <function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"XGBoost CLASSIFIER \\n\")\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(subsample=0.8, reg_lambda=0.5, reg_alpha=1, n_estimators=800, max_depth=900, learning_rate=0.01, gamma=2, colsample_bytree=0.6)\n",
    "evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, xgb_classifier, num_folds=10,model_name='xgb_classifier_smote')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 62.01038371989692\n",
      "Accuracy Test: 62.40%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.64      0.63      4623\n",
      "           1       0.63      0.61      0.62      4754\n",
      "\n",
      "    accuracy                           0.62      9377\n",
      "   macro avg       0.62      0.62      0.62      9377\n",
      "weighted avg       0.62      0.62      0.62      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2946 1677]\n",
      " [1849 2905]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM CLASSIFIER \\n\")\n",
    "from sklearn.svm import SVC\n",
    "svm__linear_classifier = SVC(probability=True)\n",
    "\n",
    "svm__linear_classifier_report,svm__linear_classifier_matrix=evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, svm__linear_classifier, num_folds=10,model_name='svm__smote_strat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABOOST CLASSIFIER \n",
      "\n",
      "Average Accuracy Train: 74.41142593086289\n",
      "Accuracy Test: 74.31%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      4623\n",
      "           1       0.75      0.75      0.75      4754\n",
      "\n",
      "    accuracy                           0.74      9377\n",
      "   macro avg       0.74      0.74      0.74      9377\n",
      "weighted avg       0.74      0.74      0.74      9377\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3418 1205]\n",
      " [1204 3550]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "ab_classifier = AdaBoostClassifier()\n",
    "print(\"ADABOOST CLASSIFIER \\n\")\n",
    "ab_classifier_report,ab_classifier_matrix=evaluate_classifier_with_kfold(X_train, y_train, X_test, y_test, ab_classifier, num_folds=10,model_name='ab_classifier_imbalanced')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
